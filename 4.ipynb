{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python 3.10\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372450 entries, 0 to 372449\n",
      "Columns: 785 entries, 0 to 0.648\n",
      "dtypes: float32(785)\n",
      "memory usage: 1.1 GB\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\divak\\OneDrive\\Documents\\python\\4.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/divak/OneDrive/Documents/python/4.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Plotting the number of occurrences of each alphabet in the dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/divak/OneDrive/Documents/python/4.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/divak/OneDrive/Documents/python/4.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(alphabet_dict\u001b[39m.\u001b[39mvalues(), dataframe[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39msort_index())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/divak/OneDrive/Documents/python/4.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mAlphabet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/divak/OneDrive/Documents/python/4.ipynb#W0sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Python 3.10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import to_categorical \n",
    "from keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Flatten\n",
    "data = pd.read_csv('A_Z Handwritten Data.csv').astype('float32')\n",
    "data.head(5)\n",
    "dataframe=pd.DataFrame(data)\n",
    "dataframe.shape\n",
    "dataframe.info()\n",
    "dataframe.describe()\n",
    "dataframe.isnull().sum()\n",
    "# Extracting labels (Y) and features (X)\n",
    "X = data.iloc[:, 1:].values\n",
    "Y = data.iloc[:, 0].values\n",
    "\n",
    "# Reshaping the images\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Shuffle the training set\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "Y_train = to_categorical(Y_train, num_classes=26)\n",
    "Y_test = to_categorical(Y_test, num_classes=26)\n",
    "# Creating a dictionary of alphabets with indexes\n",
    "alphabet_dict = {i: chr(i + 65) for i in range(26)}\n",
    "\n",
    "# Plotting the number of occurrences of each alphabet in the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(alphabet_dict.values(), dataframe[0].value_counts().sort_index())\n",
    "plt.xlabel('Alphabet')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Alphabets in the Dataset')\n",
    "plt.show()\n",
    "# Shuffle the images\n",
    "X_shuffled, Y_shuffled = shuffle(X, Y)\n",
    "\n",
    "# Display random images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    random_index = np.random.randint(0, len(X_shuffled))\n",
    "    plt.imshow(X_shuffled[random_index].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'Label: {chr(int(Y_shuffled[random_index]) + 65)}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "# Reshape train and test images for deep learning model\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming Y_train and Y_test are your float labels\n",
    "# Convert float labels to categorical labels\n",
    "Y_train_categorical = to_categorical(Y_train)\n",
    "Y_test_categorical = to_categorical(Y_test)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output before feeding into the Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # Assuming 26 classes (A-Z)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "# Train the model\n",
    "history = model.fit(X_train, Y_train_categorical, validation_data=(X_test, Y_test_categorical), epochs=3, batch_size=64)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.save(r'model_hand.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(X_test, Y_test_categorical)\n",
    "\n",
    "# Extract accuracy and loss\n",
    "accuracy = evaluation[1]\n",
    "loss = evaluation[0]\n",
    "\n",
    "# Print accuracy and loss\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
